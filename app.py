import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.linear_model import SGDClassifier
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.metrics import classification_report
from sklearn.utils.multiclass import unique_labels
import joblib
import os
# === Fonctions d‚Äôexplication et suggestion ===
def expliquer(type_erreur):
    explications = {
        "api": "Erreur sur une route API. Cela peut venir d'une mauvaise URL, m√©thode ou param√®tre.",
        "ldap": "Erreur li√©e √† l‚Äôannuaire LDAP (identifiant ou serveur).",
        "authentification": "Les identifiants fournis semblent incorrects.",
        "base_de_donnees": "Probl√®me d‚Äôacc√®s ou de requ√™te vers la base PostgreSQL.",
        "r√©seau": "Le service distant n‚Äôa pas r√©pondu ou a mis trop de temps.",
        "autre": "Erreur inconnue ou pas encore cat√©goris√©e."
    }
    return explications.get(type_erreur, "Pas d‚Äôexplication disponible.")

def suggerer_solution(type_erreur):
    suggestions = {
        "api": "V√©rifie le endpoint, les param√®tres et regarde les logs du backend.",
        "ldap": "Confirme l'identifiant ou contacte un administrateur LDAP.",
        "authentification": "Teste avec un autre utilisateur ou r√©initialise le mot de passe.",
        "base_de_donnees": "Teste la connexion √† la base, v√©rifie les credentials ou les requ√™tes SQL.",
        "r√©seau": "V√©rifie la connexion internet ou le pare-feu.",
        "autre": "Consulte un d√©veloppeur ou analyse le log complet."
    }
    return suggestions.get(type_erreur, "Pas de suggestion disponible.")

# Titre
st.set_page_config(page_title="Classification des erreurs de logs", layout="wide")
st.title("D√©tection et apprentissage incr√©mental des erreurs de logs")

st.markdown("""
Ce mini outil vous permet de :
- Visualiser les erreurs dans les logs sous forme de graphiques
- Entra√Æner un mod√®le IA incr√©mental pour classifier automatiquement les messages d'erreur
- Tester un message d'erreur
- √âvaluer un fichier .log brut
""")
# Zone d'Aide (version styl√©e)
with st.expander("‚ÑπÔ∏è Besoin d'aide pour utiliser l'application ?", expanded=False):
    st.markdown("""
    Bienvenue dans l'outil de **d√©tection intelligente des erreurs** !

    Voici comment utiliser les fonctionnalit√©s :

    - üì• **Importer un fichier CSV** :  
      Chargez un fichier avec vos messages d'erreur et leur type connu pour entra√Æner l'intelligence artificielle.

    - üß† **Tester un message d'erreur** :  
      Tapez un message libre pour que l'IA devine automatiquement son type d'erreur.

    - üìÑ **Analyser un fichier .log ou .txt** :  
      Uploadez un fichier brut de logs pour obtenir une analyse automatique de toutes les lignes.

    - ‚úçÔ∏è **Corriger une pr√©diction** :  
      Corrigez manuellement si l'IA se trompe sur une erreur, elle apprendra imm√©diatement de vos corrections !

    - ‚ôªÔ∏è **R√©initialiser le mod√®le** :  
      Si besoin, repartez de z√©ro en supprimant l'ancien apprentissage.

    ---
    üëâ *Pensez √† entra√Æner r√©guli√®rement l'IA avec des exemples pour la rendre plus intelligente !*
    """)

# R√©initialisation du mod√®le
st.sidebar.header("Options")
if st.sidebar.button("üîÑ R√©initialiser le mod√®le"):
    for file in ["modele_incremental.pkl", "vectorizer.pkl", "label_encoder.pkl"]:
        if os.path.exists(file):
            os.remove(file)
    st.sidebar.success("Mod√®le r√©initialis√© avec succ√®s.")

# Chargement CSV
uploaded_file = st.file_uploader("Importer un fichier CSV avec colonnes `message` et `type_erreur`", type="csv")

if uploaded_file:
    df = pd.read_csv(uploaded_file)
    st.subheader("Aper√ßu des donn√©es import√©es")
    st.write(df.head())

    if 'message' in df.columns and 'type_erreur' in df.columns:
        st.subheader("R√©partition des erreurs")
        st.bar_chart(df['type_erreur'].value_counts())

        X = df['message']
        y = df['type_erreur']

        label_encoder = LabelEncoder()
        y_encoded = label_encoder.fit_transform(y)

        model_loaded = False
        if all(os.path.exists(f) for f in ["modele_incremental.pkl", "vectorizer.pkl", "label_encoder.pkl"]):
            model = joblib.load("modele_incremental.pkl")
            vectorizer = joblib.load("vectorizer.pkl")
            label_encoder = joblib.load("label_encoder.pkl")
            model_loaded = True
        else:
            vectorizer = CountVectorizer()
            X_vectorized = vectorizer.fit_transform(X)

            class_counts = pd.Series(y_encoded).value_counts()
            if (class_counts < 2).any():
                st.error("Chaque classe doit avoir au moins 2 exemples.")
            else:
                model = SGDClassifier()
                model.partial_fit(X_vectorized, y_encoded, classes=list(set(y_encoded)))

                # Sauvegarde
                joblib.dump(model, "modele_incremental.pkl")
                joblib.dump(vectorizer, "vectorizer.pkl")
                joblib.dump(label_encoder, "label_encoder.pkl")
                model_loaded = True

        if model_loaded:
            X_vectorized = vectorizer.transform(X)
            y_pred = model.predict(X_vectorized)

            labels = unique_labels(y_encoded, y_pred)
            report = classification_report(
                y_encoded, y_pred,
                labels=labels,
                target_names=label_encoder.inverse_transform(labels),
                output_dict=True
            )
            st.subheader("Rapport de classification")
            st.dataframe(pd.DataFrame(report).transpose())

            # Test manuel
            st.subheader("Tester une pr√©diction manuelle")
            user_input = st.text_area("Tape un message d‚Äôerreur pour pr√©diction")
            if user_input:
                X_test = vectorizer.transform([user_input])
                y_pred = model.predict(X_test)
                pred_label = label_encoder.inverse_transform(y_pred)[0]

                st.success(f"Type d'erreur pr√©dit  : **{pred_label}**")
                # Ajout d‚Äôune explication et d‚Äôune solution avec style
                explication = expliquer(pred_label)
                suggestion = suggerer_solution(pred_label)

                st.info(f"**Explication :** {explication}")
                st.warning(f"**Suggestion :** {suggestion}")

            # Ajout d'un exemple manuel
            st.subheader("Apprentissage d‚Äôun nouveau message")
            new_message = st.text_input("Message")
            new_label = st.text_input("Type d'erreur associ√©")

            if st.button("Apprendre ce nouvel exemple"):
                if new_message and new_label:
                    try:
                        new_vector = vectorizer.transform([new_message])
                        new_encoded = label_encoder.transform([new_label])
                        model.partial_fit(new_vector, new_encoded)
                        joblib.dump(model, "modele_incremental.pkl")
                        st.success("Le mod√®le a appris ce nouveau message.")
                    except:
                        st.warning("Cette classe est inconnue. Merci d‚Äôajouter cette classe via un nouveau CSV et r√©entra√Æner.")
                else:
                    st.warning("Remplis les deux champs.")
    else:
        st.error("Le fichier doit contenir les colonnes `message` et `type_erreur`.")
else:
    st.info("Veuillez importer un fichier CSV pour commencer.")

# √âvaluation fichier .log brut
st.subheader("Analyser un fichier de logs brut (.log / .txt)")
log_file = st.file_uploader("Importer un fichier .log ou .txt", type=["log", "txt"], key="log_file")

if log_file and os.path.exists("modele_incremental.pkl"):
    try:
        model = joblib.load("modele_incremental.pkl")
        vectorizer = joblib.load("vectorizer.pkl")
        label_encoder = joblib.load("label_encoder.pkl")

        # Lecture lignes
        log_lines = log_file.read().decode("utf-8").splitlines()
        log_lines = [line for line in log_lines if line.strip() != ""]

        if len(log_lines) == 0:
            st.warning("Fichier vide.")
        else:
            X_log = vectorizer.transform(log_lines)
            preds = model.predict(X_log)
            labels = label_encoder.inverse_transform(preds)

            log_df = pd.DataFrame({
                "Ligne du log": log_lines,
                "Type d'erreur pr√©dit": labels
            })

            def color_ligne(row):
                couleur = {
                    "api": "background-color: #FFD700",
                    "ldap": "background-color: #ADD8E6",
                    "authentification": "background-color: #FFB6C1",
                    "base_de_donnees": "background-color: #90EE90",
                }
                return [couleur.get(row["Type d'erreur pr√©dit"], "")] * 2
            st.write("### R√©sultat de l‚Äôanalyse avec surlignage par type d'erreur")
            # Liste des types d‚Äôerreurs pr√©dits
            types_uniques = sorted(log_df["Type d'erreur pr√©dit"].unique())
            # Filtre multi-s√©lection
            filtre = st.multiselect("Filtrer par type d'erreur :", types_uniques, default=types_uniques)
            # Filtrage du tableau
            log_df_filtr√© = log_df[log_df["Type d'erreur pr√©dit"].isin(filtre)]
            # Compteur dynamique
            st.markdown("#### R√©sum√© des types s√©lectionn√©s :")
            for type_ in filtre:
                nb = (log_df_filtr√©["Type d'erreur pr√©dit"] == type_).sum()
                st.markdown(f"- **{type_}** : {nb} logs")
            # Affichage styl√©
            st.dataframe(log_df_filtr√©.style.apply(color_ligne, axis=1))
            st.subheader("Corriger manuellement une ligne analys√©e")

            # S√©lection de la ligne √† corriger
            ligne_selectionnee = st.selectbox("Choisir une ligne de log :", log_df_filtr√©["Ligne du log"].tolist())

            # Pr√©diction actuelle
            prediction_actuelle = log_df_filtr√©[log_df_filtr√©["Ligne du log"] == ligne_selectionnee]["Type d'erreur pr√©dit"].values[0]
            st.markdown(f"**Pr√©diction actuelle** : `{prediction_actuelle}`")

            # S√©lection de la bonne classe
            type_correction = st.selectbox("S√©lectionner le bon type :", label_encoder.classes_, key="correction_log")

            if st.button("Corriger et r√©entra√Æner avec cette ligne"):
                X_correction = vectorizer.transform([ligne_selectionnee])
                y_correction = label_encoder.transform([type_correction])
                model.partial_fit(X_correction, y_correction)
                joblib.dump(model, "modele_incremental.pkl")
                st.success(f"Correction enregistr√©e : le mod√®le a appris que cette ligne est une erreur **{type_correction}**")


            csv = log_df.to_csv(index=False).encode("utf-8")
            st.download_button("T√©l√©charger les pr√©dictions (CSV)", csv, file_name="logs_analyzes.csv")
    except Exception as e:
        st.error(f"Erreur : {e}")